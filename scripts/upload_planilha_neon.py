import pandas as pd
import psycopg2
import logging
import os
from tqdm import tqdm

# Configura√ß√µes das vari√°veis de ambiente (GitHub Actions)
DATABASE_URL = os.getenv('DATABASE_URL')
TABELA = os.getenv('TABELA', 'cadastros')
PLANILHA = 'Emitir.xlsx'  # Nome fixo no GitHub Actions

# Valida√ß√£o
if not DATABASE_URL:
    raise ValueError("DATABASE_URL n√£o definida nos secrets do GitHub")

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("upload_neon.log"),
        logging.StreamHandler()
    ]
)

def verificar_conexao_neon():
    """Verifica a conex√£o com o Neon"""
    try:
        with psycopg2.connect(DATABASE_URL) as conn:
            logging.info("‚úÖ Conex√£o com Neon estabelecida")
        return True
    except Exception as e:
        logging.error(f"‚ùå Erro ao conectar: {e}")
        return False

def limpar_tabela():
    """Limpa a tabela antes do upload"""
    try:
        with psycopg2.connect(DATABASE_URL) as conn:
            with conn.cursor() as cur:
                logging.info(f"üóëÔ∏è Limpando tabela {TABELA}...")
                cur.execute(f'DELETE FROM public.{TABELA}')
                conn.commit()
                logging.info("‚úÖ Tabela limpa")
    except Exception as e:
        logging.error(f"‚ùå Erro ao limpar tabela: {e}")
        raise

def upload_planilha():
    """Upload da planilha para o Neon"""
    try:
        # Ler Excel
        df = pd.read_excel(PLANILHA)
        logging.info(f"üìä Lidas {len(df)} linhas do Excel")
        
        # Normalizar colunas
        df.columns = [col.upper().strip() for col in df.columns]
        logging.info(f"Colunas: {list(df.columns)}")
        
        sucessos = 0
        erros = 0

        with psycopg2.connect(DATABASE_URL) as conn:
            with conn.cursor() as cur:
                with tqdm(total=len(df), desc="Importando") as pbar:
                    for index, row in df.iterrows():
                        dados = row.dropna().to_dict()
                        dados_limpos = {f'"{key}"': value for key, value in dados.items()}

                        cols = ', '.join(dados_limpos.keys())
                        vals = ', '.join(['%s'] * len(dados_limpos))
                        query = f"INSERT INTO public.{TABELA} ({cols}) VALUES ({vals})"
                        
                        try:
                            cur.execute(query, list(dados_limpos.values()))
                            conn.commit()
                            sucessos += 1
                            pbar.set_postfix({"‚úÖ": sucessos, "‚ùå": erros})
                        except Exception as e:
                            conn.rollback()
                            erros += 1
                            logging.warning(f"Erro linha {index + 1}: {e}")
                            pbar.set_postfix({"‚úÖ": sucessos, "‚ùå": erros})
                        
                        pbar.update(1)
        
        logging.info(f"‚úÖ Importa√ß√£o conclu√≠da: {sucessos} sucessos, {erros} erros")
        return sucessos, erros
                
    except FileNotFoundError:
        logging.error(f"‚ùå Arquivo {PLANILHA} n√£o encontrado")
        raise
    except Exception as e:
        logging.error(f"‚ùå Erro no upload: {e}")
        raise

if __name__ == "__main__":
    try:
        logging.info("üöÄ Iniciando upload para Neon...")
        
        if not verificar_conexao_neon():
            exit(1)
        
        # No GitHub Actions, sempre limpa a tabela
        limpar_tabela()
        
        sucessos, erros = upload_planilha()
        
        if erros > 0:
            logging.warning(f"‚ö†Ô∏è Conclu√≠do com {erros} erros")
            exit(1)
        else:
            logging.info("‚úÖ Upload 100% conclu√≠do")
        
    except Exception as e:
        logging.error(f"‚ùå Erro fatal: {e}")
        exit(1)
